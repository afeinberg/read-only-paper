\section{Conclusion / Future Work}
\label{sec:conclusion}

In this paper we present a low-latency bulk loading system capable of serving multiple TBs of data. By moving the index construction offline to a batch system like Hadoop, we make our serving layer's performance more reliable. \\linkedin{} has successfully been running read-only \projectname{} clusters for the past 2 years. It has become an integral part of the product eco-system with various engineers also using it frequently for quick prototypes of products. 

There are still some interesting functionalities that we would like to add to the read-only storage pipeline. Firstly, we want to add support for incremental loads. We do have an initial prototype in which we create patches for the data files on the Hadoop side (by comparing against the snapshot of the previously loaded data still in HDFS) and then apply these on the \projectname{} side during the fetch. We don't do any patch generation for the index files and just send them over since (a) they are relatively small files (b) we want to exploit the OS caching during the fetch. We are still exploring the use of this functionality since most of our current stores are recommendation products where the values, represented by floats for probabilities, generally change between iterations for most users. 

Another important feature that we want to add to the fetch pipeline is the ability to only fetch one replica of the data from HDFS and then propagate it further on the \projectname{} node. Over time we have found that during fetches we exhaust the full bandwidth between the data-centers running Hadoop (in particular HDFS) and Voldemort. In such a scenario optimizing the amount of data being transferred between data-centers can be a great plus. We have also tried compressing the complete data before storing it in HDFS and then un-compressing this on the fly on the \projectname{} side. Unfortunately this isn't that helpful in scenarios where the users have decided to use the per-key based compression since we are already dealing with compressed data. 

Finally we would definitely like to explore some more index structures which would make lookups faster and can be built in Hadoop easily. In particular a lot of work has been done in the area of cache oblivious trees, like van Emde Boas trees, which requires no knowledge of page size to get optimal cache performance. 
