\begin{abstract}
Project \projectname{} is a distributed storage and serving system inspired from Amazon's Dynamo. This paper presents a novel storage pipeline, for massive read-only data, which fits into \projectname{} and leverages the inherent fault tolerance and scalability of the Dynamo architecture. \projectname{} solves the problem that most current serving systems face of not being able to consume huge data-sets without affecting serving performance. The data generation in this pipeline is done offline using Hadoop, thereby bridging the gap between batch oriented and serving systems. As a production system at \linkedin{}, this has helped us iterate on various data-intensive social products offline and then publish the multi-TBs size output to the site, multiple times in a day. 
\end{abstract}
