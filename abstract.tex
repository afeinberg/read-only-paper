\begin{abstract}
Project \projectname{} is a general purpose distributed storage and serving system inspired by Amazon's Dynamo. We present a novel pipeline for computing, deploying and serving massive read-only data sets that we have integrated into \projectname{}. This pipeline builds on the inherent fault-tolerance and horizontal scalability of the Dynamo architecture to solve a common problem: performing massive data loads into an online system without impacting serving performance. The data generation is done offline using Hadoop, while our system effectively bridges the gap between batch-oriented clusters and real-time serving systems. As a production system at \linkedin{}, \projectname{} has helped us rapidly build out various data-intensive social products using offline computation, and then publish the resulting multi-TB output data to live production throughout the day.
\end{abstract}
